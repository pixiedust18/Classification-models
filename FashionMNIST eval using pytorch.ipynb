{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport matplotlib.pylab as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_data(data_sample):\n    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n    plt.title('y = '+ str(data_sample[1].item()))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_channels(W):\n    n_out = W.shape[0]\n    n_in = W.shape[1]\n    w_min = W.min().item()\n    w_max = W.max().item()\n    fig, axes = plt.subplots(n_out, n_in)\n    fig.subplots_adjust(hspace=0.1)\n    out_index = 0\n    in_index = 0\n    \n    #plot outputs as rows inputs as columns \n    for ax in axes.flat:\n        if in_index > n_in-1:\n            out_index = out_index + 1\n            in_index = 0\n        ax.imshow(W[out_index, in_index, :, :], vmin=w_min, vmax=w_max, cmap='seismic')\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])\n        in_index = in_index + 1\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_parameters(W, number_rows=1, name=\"\", i=0):\n    W = W.data[:, i, :, :]\n    n_filters = W.shape[0]\n    w_min = W.min().item()\n    w_max = W.max().item()\n    fig, axes = plt.subplots(number_rows, n_filters // number_rows)\n    fig.subplots_adjust(hspace=0.4)\n\n    for i, ax in enumerate(axes.flat):\n        if i < n_filters:\n            # Set the label for the sub-plot.\n            ax.set_xlabel(\"kernel:{0}\".format(i + 1))\n\n            # Plot the image.\n            ax.imshow(W[i, :], vmin=w_min, vmax=w_max, cmap='seismic')\n            ax.set_xticks([])\n            ax.set_yticks([])\n    plt.suptitle(name, fontsize=10)    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nIMAGE_SIZE = 16\n\n\ncomposed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = dsets.FashionMNIST(root='./projectdata', train=True, transform=composed, download=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_dataset = dsets.FashionMNIST(root='./projectdata', train=False, download=True, transform=composed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_data(train_dataset[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_data(train_dataset[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNN(nn.Module):\n    \n    def __init__(self, out_1=16, out_2=32, p=0.25):\n        super(CNN, self).__init__()\n        self.drop1 = nn.Dropout(p=p)\n        self.drop2 = nn.Dropout(p=p)\n\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n        self.conv1_bn = nn.BatchNorm2d(out_1)\n\n        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n        \n        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n        self.conv2_bn = nn.BatchNorm2d(out_2)\n\n        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n        self.fc1 = nn.Linear(out_2 * 4 * 4, 10)\n        self.fc_bn = nn.BatchNorm1d(10)\n        \n    def forward(self, x):\n        x = self.cnn1(x)\n        x = self.conv1_bn(x)\n        x = self.maxpool1(x)\n        x = self.cnn2(x)\n        x = self.conv2_bn(x)\n        x = self.maxpool2(x)\n        x = self.drop2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.fc_bn(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model,train_loader,validation_loader,optimizer,n_epochs=4):\n    \n    #global variable \n    N_test=len(validation_dataset)\n    accuracy_list=[]\n    loss_list=[]\n    \n    for epoch in range(n_epochs):\n        temp_loss=0\n        for x, y in train_loader:\n            model.train()\n            optimizer.zero_grad()\n            z = model(x)\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            temp_loss+=loss.item()\n        loss_list.append(temp_loss)\n        correct=0\n        #perform a prediction on the validation  data  \n        for x_test, y_test in validation_loader:\n            model.eval()\n            z = model(x_test)\n            _, yhat = torch.max(z.data, 1)\n            correct += (yhat == y_test).sum().item()\n        accuracy = correct / N_test\n        accuracy_list.append(accuracy)\n        \n        print(\n                'Train Epoch: ', epoch, ' \\n loss= ', temp_loss, ' accuracy= ', accuracy, '\\n')\n     \n    return accuracy_list, loss_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = CNN(out_1=16, out_2=32)\n#absolute_accuracy_list=[]\n#absolute_loss_list=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_list_normal, loss_list_normal = train_model(model=model,n_epochs=40,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlim=len(absolute_loss_list)\nfig, ax1 = plt.subplots()\naxes = plt.gca()\naxes.set_xlim([0,xlim])\naxes.set_ylim([0,400])\ncolor = 'tab:red'\nax1.plot(loss_list_normal, color=color)\nax1.set_xlabel('epoch', color=color)\nax1.set_ylabel('Cost', color=color)\nax1.tick_params(axis='y', color=color)\n\nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color) \nax2.set_xlabel('epoch', color=color)\nax2.plot( accuracy_list_normal, color=color)\nax2.tick_params(axis='y', color=color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.h5')\nabsolute_accuracy_list=absolute_accuracy_list+accuracy_list_normal\nabsolute_loss_list=absolute_loss_list+loss_list_normal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_list_normal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(absolute_accuracy_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(absolute_loss_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlim=len(absolute_loss_list)\nfig, ax1 = plt.subplots()\naxes = plt.gca()\naxes.set_xlim([0,xlim])\naxes.set_ylim([0,400])\ncolor = 'tab:red'\nax1.plot(absolute_loss_list, color=color)\nax1.set_xlabel('epoch', color=color)\nax1.set_ylabel('Cost', color=color)\nax1.tick_params(axis='y', color=color)\n\nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color) \nax2.set_xlabel('epoch', color=color)\nax2.plot( absolute_accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}